# ğŸ¤– Smart AI Agent (Gemma3 + Web Tools)

An intelligent Streamlit-based assistant that runs **Gemma3:4b** locally via Ollama and automatically switches between:

- ğŸŒ **Online mode:** Uses Wikipedia + DuckDuckGo search for live data.
- ğŸ“´ **Offline mode:** Uses Gemma3:4b alone (with a warning about outdated info).

---

## ğŸš€ Features

- ğŸ§  Local reasoning via **Gemma3:4b**
- ğŸŒ Web search via **Wikipedia** and **DuckDuckGo**
- ğŸ’¬ Chat memory across turns
- ğŸ§¹ "Clear Chat" button
- âš™ï¸ Clean modular structure for maintainability

---

## ğŸ§± Project Structure

```
app/
â”œâ”€â”€ main.py # Streamlit app
â”œâ”€â”€ agent_logic.py # Main agent logic (ReAct + fallback)
â”œâ”€â”€ prompts.py # Prompt templates
â”œâ”€â”€ utils.py # Internet check helper
â””â”€â”€ init.py
requirements.txt
README.md
```





## ğŸ§© Installation (Local)

### 1ï¸âƒ£ Install Ollama
Install [Ollama](https://ollama.com/download) and pull Gemma:

```bash
ollama pull gemma3:4b


### 2ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/AAliAhmadi/smart-agent.git
cd smart-agent

### 3ï¸âƒ£ Set up environment
```bash
python -m venv .venv
source .venv/bin/activate   # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

### 4ï¸âƒ£ Run locally
```bash
streamlit run app/main.py


## ğŸ§  Usage

Run the app and start chatting:

Ask factual or reasoning-based questions.

If internet is available, the agent searches online.

If not, it answers locally but notes that info might be outdated.

Use the ğŸ—‘ï¸ Clear Chat History button to reset the conversation.



## Acknowledgement
ğŸ™ This project was inspired by the lectures of Bharath Thippireddy.



## ğŸ“„ License

MIT License Â© 2025 AAli Ahmadi

âœ… **Summary of Improvements**
- Cleaner modular structure (`main`, `logic`, `prompts`, `utils`)
- Visible chat history  
- â€œğŸ—‘ï¸ Clear Chat Historyâ€ button  
- Ready for both **local** (Gemma) and **cloud** (GPT/OpenAI) modes  
- Updated, professional README  

---

Would you like me to make a **Streamlit Cloudâ€“compatible variant** (automatically detects if Ollama is missing, and uses GPT-4o instead)? Itâ€™ll run both locally *and* in the cloud with no edits.


